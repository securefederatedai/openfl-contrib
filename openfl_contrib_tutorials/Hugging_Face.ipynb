{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59f475d-d843-46bc-b75e-10984b687ed3",
   "metadata": {},
   "source": [
    "# Federated Fine-Tuning of a Hugging Face Model Using OpenFL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c74cb9-51a2-42e2-893f-d280e227e8bf",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we demonstrate how to fine-tune a Hugging Face Transformers model i.e BERT in a federated learning workflow.\n",
    "\n",
    "We will fine-tune Hugging Face Transformers model using a diverse dataset such as [Math_10k](https://github.com/AGI-Edgerunners/LLM-Adapters/tree/main), an open-source dataset containing mathematical question-answer pairs collected from various smaller math datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c32d3-1a8d-4162-af45-bc3a10e0ae3f",
   "metadata": {},
   "source": [
    "## The Workflow Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d74610-e48d-4dd4-b622-eb910fbe91aa",
   "metadata": {},
   "source": [
    "The workflow interface is an innovative approach to designing federated learning experiments with OpenFL. It was developed in response to discussions with researchers and users who had unique use cases that didnâ€™t perfectly align with the traditional horizontal federated learning model. This interface enables more flexible compositions of experiments, allowing for greater customization and adaptability in complex, real-world scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e1d95-fd76-4fe0-b8d0-4c625c2a8fd3",
   "metadata": {},
   "source": [
    "## Installing OpenFL\n",
    "To install OpenFL, follow the official documentation: \n",
    "[OpenFL Installation Guide](https://openfl.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53654c70",
   "metadata": {},
   "source": [
    "After installation, activate experimental APIs using:   \n",
    "`fx experimental activate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b2ad75-8c7b-499c-902e-dbd5b24361bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies \n",
    "!pip install torch transformers peft datasets trl==0.12.2 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a9c39-ec42-45a5-80f6-9a9e0bc90d2f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4690ae-0671-4d3a-8f21-620ab865a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.utils import get_peft_model_state_dict, set_peft_model_state_dict\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding \n",
    "from transformers.trainer_callback import PrinterCallback\n",
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08576aa0-f628-4ae6-8fc3-dd167d164784",
   "metadata": {},
   "source": [
    "## Acquiring and preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1d8b6-8a5b-41a2-8c77-c9a85e869cda",
   "metadata": {},
   "source": [
    "We can download the dataset directly from the [LLM-Adapters repository](https://github.com/AGI-Edgerunners/LLM-Adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615d626-8727-4169-b2a6-3ba15c3cdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_checksum(file_path, algorithm=\"sha256\"):\n",
    "    \"\"\"\n",
    "    Calculate the checksum of a file using the specified hashing algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the file for which the checksum is to be calculated.\n",
    "    algorithm (str): The hashing algorithm to use (default is 'sha256').\n",
    "\n",
    "    Returns:\n",
    "    str: The calculated checksum of the file.\n",
    "    \"\"\"\n",
    "    hash_func = hashlib.new(algorithm)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_func.update(chunk)\n",
    "    return hash_func.hexdigest()\n",
    "\n",
    "\n",
    "if not os.path.exists(\"math_10k.json\"):\n",
    "    r = requests.get(\n",
    "        \"https://raw.githubusercontent.com/AGI-Edgerunners/LLM-Adapters/main/ft-training_set/math_10k.json\",\n",
    "    )\n",
    "    with open(\n",
    "        \"math_10k.json\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    actual_checksum = file_checksum(\"math_10k.json\")\n",
    "    if (\n",
    "        actual_checksum\n",
    "        != \"0342d0d860ad8592b579329337c90e42eefd3d9f2898043140cbd120630418b8\"\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Checksum verification failed. The file may have been altered.\"\n",
    "        )\n",
    "\n",
    "raw_dataset = load_dataset(\"json\", data_files=\"math_10k.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab15ad6-db35-4a58-a2d5-54a6d3ccdc78",
   "metadata": {},
   "source": [
    "## Initialize arguments and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eada9809-468a-47c6-9b03-55aa887c9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"use_cpu\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
    "    \"warmup_ratio\": 0.2,\n",
    "}\n",
    "\n",
    "peft_config = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",  # Sequence classification task\n",
    "    \"target_modules\": [\"query\", \"value\"],    # Target modules for LoRA\n",
    "}\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None,\n",
    ")\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe93234-2a1a-4809-a431-efe2f35ce496",
   "metadata": {},
   "source": [
    "## Load and initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab371f1-64c3-4225-82e7-fb3c5b05578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"bert-base-uncased\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path, return_dict=True, num_labels=2, **model_kwargs\n",
    ")\n",
    "model = get_peft_model(model, peft_conf)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "sequence_max_length = 512\n",
    "val_set_size = 2000\n",
    "tokenizer.pad_token_id = 0  # we want this to be different from the eos token\n",
    "tokenizer.padding_side = \"left\"  # Allow batched inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd058fff-f6dd-4cc6-acaf-7e2fa2c1132d",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0fc94-9b4e-4171-a0dc-58faecf75f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    \"\"\"\n",
    "    Generate a prompt based on the given data point.\n",
    "\n",
    "    Parameters:\n",
    "    data_point (dict): A dictionary containing the instruction, input, and output.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated prompt as a string.\n",
    "    \"\"\"\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "\n",
    "                ### Instruction:\n",
    "                {data_point[\"instruction\"]}\n",
    "                \n",
    "                ### Input:\n",
    "                {data_point[\"input\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {data_point[\"output\"]}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.  \n",
    "\n",
    "                ### Instruction:\n",
    "                {data_point[\"instruction\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "def tokenize(data_point, add_eos_token=True):\n",
    "    \"\"\"\n",
    "    Tokenize the given data point and set the correct labels for sequence classification.\n",
    "    \"\"\"\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    result = tokenizer(\n",
    "        full_prompt,\n",
    "        truncation=True,\n",
    "        max_length=sequence_max_length,\n",
    "        padding=\"max_length\",        \n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    \"\"\"\n",
    "    Generate and tokenize a prompt based on the given data point.\n",
    "    \"\"\"\n",
    "    return tokenize(data_point)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_val = raw_dataset[\"train\"].train_test_split(\n",
    "    test_size=val_set_size, shuffle=True, seed=42\n",
    ")\n",
    "\n",
    "# Process the datasets\n",
    "processed_train_dataset = train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt).select(range(10))\n",
    "processed_test_dataset = train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt).select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812cfcc8-33ec-4a2b-8a74-27bfc2a41d7b",
   "metadata": {},
   "source": [
    "## Define Federated Averaging Method\n",
    "The FedAvg method is used to average the models from all the collaborators after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dc85c57-68b2-4514-9373-43e3d7c05c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(peft_params, model, weights=None):\n",
    "    \"\"\"\n",
    "    Perform Federated Averaging (FedAvg) on the model parameters.\n",
    "\n",
    "    Parameters:\n",
    "    peft_params (list): A list of state dictionaries containing the model parameters from different clients.\n",
    "    model (torch.nn.Module): The model to which the averaged parameters will be applied.\n",
    "    weights (list, optional): A list of weights for averaging the parameters. If None, equal weights are used.\n",
    "\n",
    "    Returns:\n",
    "    torch.nn.Module: The model with the averaged parameters applied.\n",
    "    \"\"\"\n",
    "    state_dicts = peft_params\n",
    "    state_dict = get_peft_model_state_dict(model)\n",
    "    for key in peft_params[0]:\n",
    "        dtype = state_dicts[0][key].dtype\n",
    "        state_dict[key] = torch.from_numpy(\n",
    "            np.average(\n",
    "                [state[key].to(torch.float).numpy() for state in state_dicts], axis=0, weights=weights\n",
    "            )\n",
    "        ).to(dtype)\n",
    "    set_peft_model_state_dict(model, state_dict)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "810eb75e",
   "metadata": {},
   "source": [
    "Now we come to the flow definition. The OpenFL Workflow Interface adopts the conventions set by Metaflow, that every workflow begins with `start` and concludes with the `end` task. The aggregator begins with an optionally passed in model and optimizer. The aggregator begins the flow with the `start` task, where the list of collaborators is extracted from the runtime (`self.collaborators = self.runtime.collaborators`) and is then used as the list of participants to run the task listed in `self.next`, `aggregated_model_validation`. The model, optimizer, and anything that is not explicitly excluded from the next function will be passed from the `start` function on the aggregator to the `aggregated_model_validation` task on the collaborator. Where the tasks run is determined by the placement decorator that precedes each task definition (`@aggregator` or `@collaborator`). Once each of the collaborators (defined in the runtime) complete the `aggregated_model_validation` task, they pass their current state onto the `train` task, from `train` to `local_model_validation`, and then finally to `join` at the aggregator. It is in `join` that an average is taken of the model weights, and the next round can begin.\n",
    "\n",
    "![Workflow Interface](../../../../docs/images/workflow_interface.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58298e8e-ab9e-4377-966e-143823441697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator step \"start\" registered\n",
      "Collaborator step \"aggregated_model_validation\" registered\n",
      "Collaborator step \"train\" registered\n",
      "Collaborator step \"local_model_validation\" registered\n",
      "Aggregator step \"join\" registered\n",
      "Aggregator step \"end\" registered\n"
     ]
    }
   ],
   "source": [
    "class FederatedFlow(FLSpec):\n",
    "    def __init__(self, model=None, optimizer=None, rounds=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the class with the given model, optimizer, and number of rounds.\n",
    "\n",
    "        Parameters:\n",
    "        model (torch.nn.Module, optional): The model to be used. If None, a ValueError is raised.\n",
    "        optimizer (torch.optim.Optimizer, optional): The optimizer to be used.\n",
    "        rounds (int, optional): The number of rounds for training or processing (default is 3).\n",
    "        **kwargs: Additional keyword arguments to be passed to the superclass initializer.\n",
    "\n",
    "        Raises:\n",
    "        ValueError: If no model is provided.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.peft_params = get_peft_model_state_dict(self.model)\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            raise ValueError(\"No model inputted\")\n",
    "\n",
    "        self.rounds = rounds\n",
    "        \n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Initialize the model and set up the collaborators for federated learning.\n",
    "\n",
    "        This method performs the initial setup for the model, including setting the\n",
    "        collaborators, initializing private variables, and starting the first round\n",
    "        of the federated learning process.\n",
    "        \"\"\"\n",
    "        print(f\"Performing initialization for model\")\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.current_round = 0\n",
    "        self.next(\n",
    "            self.aggregated_model_validation,\n",
    "            foreach=\"collaborators\",\n",
    "        )\n",
    "\n",
    "    \n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        \"\"\"\n",
    "        Perform aggregated model validation for a collaborator.\n",
    "\n",
    "        This method loads the model, applies the PEFT configuration, and evaluates\n",
    "        the model using the provided training and evaluation datasets. The validation\n",
    "        score is then stored and the next step in the process is triggered.\n",
    "        \"\"\"\n",
    "        print(f\"Performing aggregated model validation for collaborator {self.input}\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            checkpoint_path, return_dict=True, num_labels=2, **model_kwargs\n",
    "        )\n",
    "        self.model = get_peft_model(self.model, peft_conf)\n",
    "        set_peft_model_state_dict(self.model, self.peft_params)\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=train_conf,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.eval_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        trainer.remove_callback(PrinterCallback)\n",
    "        out = trainer.evaluate()\n",
    "        self.agg_validation_score = out[\"eval_loss\"]\n",
    "        print(f\"{self.input} value of {self.agg_validation_score}\")\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model for a collaborator.\n",
    "\n",
    "        This method trains the model using the provided training and evaluation datasets.\n",
    "        The training loss is stored, the model is saved, and the next step in the process\n",
    "        is triggered.\n",
    "        \"\"\"\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=train_conf,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.eval_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        out = trainer.train()\n",
    "        self.loss = out.training_loss\n",
    "        trainer.save_model()\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        \"\"\"\n",
    "        Perform local model validation for a collaborator.\n",
    "\n",
    "        This method evaluates the model using the provided training and evaluation datasets.\n",
    "        The validation score is stored, the PEFT parameters are updated, and the next step\n",
    "        in the process is triggered.\n",
    "        \"\"\"\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=train_conf,\n",
    "            train_dataset=self.train_dataset,  # Use collaborator-specific dataset\n",
    "            eval_dataset=self.eval_dataset, \n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        out = trainer.evaluate()\n",
    "        self.local_validation_score = out[\"eval_loss\"]\n",
    "        self.peft_params = get_peft_model_state_dict(self.model)\n",
    "        print(f\"Doing local model validation for collaborator {self.input}\")\n",
    "        self.next(self.join, exclude=[\"training_completed\", \"model\"])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        \"\"\"\n",
    "        Aggregate the results from all collaborators and update the model.\n",
    "\n",
    "        This method calculates the average loss, aggregated model accuracy, and local model\n",
    "        accuracy from all collaborators. The model parameters are updated using Federated\n",
    "        Averaging (FedAvg), and the next round of the process is triggered if applicable.\n",
    "        \"\"\"\n",
    "        self.average_loss = sum(input.loss for input in inputs) / len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(\n",
    "            input.agg_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        self.local_model_accuracy = sum(\n",
    "            input.local_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        print(\n",
    "            f\"Average aggregated model validation values = {self.aggregated_model_accuracy}\"\n",
    "        )\n",
    "        print(f\"Average training loss = {self.average_loss}\")\n",
    "        print(f\"Average local model validation values = {self.local_model_accuracy}\")\n",
    "\n",
    "        self.model = FedAvg([input.peft_params for input in inputs], self.model)\n",
    "        self.peft_params = get_peft_model_state_dict(self.model)\n",
    "\n",
    "        self.model.save_pretrained(\"./aggregated/model\")\n",
    "        tokenizer.save_pretrained(\"./aggregated/tokenizer\")\n",
    "        self.current_round += 1\n",
    "        if self.current_round < self.rounds:\n",
    "            self.next(\n",
    "                self.aggregated_model_validation,\n",
    "                foreach=\"collaborators\",\n",
    "                exclude=[\"model\"],\n",
    "            )\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End the federated learning process.\n",
    "\n",
    "        This method marks the end of the federated learning process and performs any\n",
    "        necessary cleanup or finalization steps.\n",
    "        \"\"\"\n",
    "        print(f\"This is the end of the flow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120a656-f4a5-47a5-a3d4-62c5f3672bba",
   "metadata": {},
   "source": [
    "You'll notice in the `FederatedFlow` definition above that there were certain attributes that the flow was not initialized with, namely the `train_dataset` and `eval_dataset` for each of the collaborators. These are **private_attributes** that are exposed only through the runtime. Each participant has its own set of private attributes: a dictionary where the key is the attribute name, and the value is the object that will be made accessible through that participant's task.\n",
    "\n",
    "Below, we segment shards of the Math_10k dataset for **two collaborators**: Portland and Seattle. Each has their own slice of the dataset that's accessible via the `train_dataset` or `eval_dataset` attribute. Note that the private attributes are flexible, and you can choose to pass in a completely different type of object to any of the collaborators or aggregator (with an arbitrary name). These private attributes will always be filtered out of the current state when transfering from collaborator to aggregator, or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e108c6-5150-4931-9c01-6b64a913fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup participants\n",
    "_aggregator = Aggregator()\n",
    "_aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = [\n",
    "    \"Portland\",\n",
    "    \"Seattle\",\n",
    "]\n",
    "_collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "\n",
    "for idx, current_collaborator in enumerate(_collaborators):\n",
    "    # Set the private attributes of the Collaborator to include their specific training and testing data loaders\n",
    "    current_collaborator.private_attributes = {\n",
    "        \"train_dataset\": processed_train_dataset.shard(\n",
    "            num_shards=len(_collaborators), index=idx\n",
    "        ),\n",
    "        \"eval_dataset\": processed_test_dataset.shard(\n",
    "            num_shards=len(_collaborators), index=idx\n",
    "        ),\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=_aggregator, collaborators=_collaborators, backend=\"single_process\"\n",
    ")\n",
    "print(f\"Local runtime collaborators = {local_runtime.collaborators}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb61fc0",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38894111-41d9-4dd4-b1c8-eb7ec3cdd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flflow = FederatedFlow(model, rounds=2)\n",
    "flflow.runtime = local_runtime\n",
    "flflow.run()\n",
    "\n",
    "# Determine the final model accuracy:\n",
    "print(f'\\nFinal aggregated model accuracy for {flflow.rounds} rounds of training: {flflow.aggregated_model_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8fe27",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations! ðŸŽ‰\n",
    "\n",
    "Now that you've completed this notebook, check out our [other tutorials](https://github.com/securefederatedai/openfl/tree/develop/openfl-tutorials/experimental/)\n",
    "\n",
    "- Using the LocalRuntime Ray Backend for dedicated GPU access\n",
    "- Vertical Federated Learning\n",
    "- Model Watermarking\n",
    "- Differential Privacy\n",
    "- And More!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
